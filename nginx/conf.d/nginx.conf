# This directive sets the number of worker processes that Nginx should use to handle incoming connections. The value "auto" indicates that Nginx will automatically determine the optimal number of worker processes based on the available CPU cores. Each worker process is essentially a separate instance of Nginx that can handle connections concurrently.
worker_processes auto;

# This directive sets the maximum core dump size (in this case, 500 megabytes) for each worker process. A core dump is a snapshot of a process's memory when it encounters a crash or a serious error. This setting restricts the size of these core dump files to prevent them from consuming excessive disk space.
worker_rlimit_nofile 8192;


events {
    # This directive disables the accept mutex. The accept mutex is a synchronization mechanism used to prevent multiple worker processes from trying to accept a new connection simultaneously. Disabling it can improve performance in certain scenarios, but it's generally used when Nginx is running in environments with high connection rates and multiple worker processes
    accept_mutex        off;

    # This directive sets the maximum number of simultaneous connections that each worker process can handle. In this case, each worker process is configured to handle up to 1024 connections simultaneously. If this limit is reached, Nginx will start queuing incoming connections until a worker becomes available.
    worker_connections  1024;

    # This directive enables the multi-accept feature. When multi-accept is enabled, Nginx will try to accept as many incoming connections as possible in a single system call, potentially improving the efficiency of accepting new connections.
    multi_accept        on;

    # This directive specifies the event mechanism to be used for event-driven I/O operations. "epoll" is a highly efficient event notification mechanism available on Linux systems. It allows Nginx to efficiently manage a large number of connections with minimal system resource usage.
    use                 epoll;

}
http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    log_format compression '$remote_addr - $remote_user [$time_local] '
                            '"$request" $status $body_bytes_sent '
                            '"$http_referer" "$http_user_agent" "$gzip_ratio"';
    
    ############ Conection Timeouts
    
    # This directive sets the maximum amount of time (in seconds) that Nginx will wait for the client to send the request body (POST data) after the initial request headers have been received. If the client takes longer than the specified timeout to send the request body, Nginx will close the connection.
    client_body_timeout     12;

    # This directive sets the maximum amount of time (in seconds) that Nginx will wait for the client to send the complete set of request headers. If the client doesn't send all the headers within the specified timeout, Nginx will close the connection.
    client_header_timeout   12;

    # This directive sets the maximum amount of time (in seconds) that a persistent connection (keep-alive connection) between the server and a client can remain open after the initial response has been sent. It defines how long the server will wait for additional requests from the same client over the same connection.
    keepalive_timeout       15;
    
    # This directive sets the maximum amount of time (in seconds) that Nginx will wait for the response to be fully transmitted to the client after the response headers have been sent. If the response transmission takes longer than the specified timeout, Nginx will close the connection.
    send_timeout            10;

    # This directive enables access logging for the server block. When set to "on," Nginx will log information about incoming requests, responses, and other relevant details to its access log files.
    access_log              on;

    # This directive enables the use of the "sendfile" system call to efficiently transmit files to clients. When set to "on," Nginx will utilize the operating system's mechanisms for optimized file transmission, which can significantly improve the speed and efficiency of serving static files.
    sendfile                on;

    # This directive enables TCP_NOPUSH option, which instructs Nginx to attempt to send the response headers and some amount of the response body in a single packet, if possible. This can help reduce the number of network packets and improve performance, especially for small responses.
    tcp_nopush              on;

    # This directive enables the TCP_NODELAY option, which disables the Nagle algorithm. This algorithm is used to reduce the number of small packets sent over the network by buffering data before sending. By enabling TCP_NODELAY, Nginx ensures that data is sent immediately without waiting for additional data to accumulate, which can reduce latency.
    tcp_nodelay             on;

    # This directive turns off the inclusion of server version information in the response headers that Nginx sends to clients. This can enhance security by preventing potential attackers from easily identifying the exact software versions being used.
    server_tokens           off;

    # This directive controls whether Nginx logs requests for files that are not found (HTTP 404 responses). When set to "off," Nginx will not generate log entries for such requests, which can help keep the access logs cleaner.
    log_not_found           off;

    # This directive sets the maximum size of the types hash table. The types hash table is used to efficiently determine MIME types for files based on their extensions. Setting a larger value can improve performance when dealing with a large number of file types.
    types_hash_max_size     2048;

    ################ Encoding with gzip

    # This directive enables Gzip compression for responses. When set to "on," Nginx will compress eligible responses before sending them to the clients.
    gzip                    on;

    # This directive specifies a list of user agent strings for which Gzip compression should be disabled. In this case, "msie6" refers to Microsoft Internet Explorer 6, which is an older browser known to have compatibility issues with Gzip compression. Disabling Gzip for such browsers can help avoid potential issues.
    gzip_disable            "msie6";

    # This directive adds the "Vary: Accept-Encoding" header to responses. This header informs caching mechanisms and intermediate proxies that the content may vary based on the client's preferred encoding (Gzip in this case). It helps ensure that compressed and uncompressed versions of a resource are cached separately.
    gzip_vary               on;

    # This directive allows Nginx to automatically decompress Gzip-encoded requests before processing them. This is useful for handling requests that clients send in compressed form.
    gunzip                  on;

    # This directive configures how Nginx handles proxies. It specifies that responses should be compressed for all clients and proxies.
    gzip_proxied            any;

    # This directive sets the compression level for Gzip. The value "9" represents the highest level of compression, which can result in smaller file sizes but might require more CPU resources to compress.
    gzip_comp_level         9;

    # This directive defines the number and size of buffers used for Gzip compression. It specifies that Nginx should use 16 buffers, each with a size of 8 kilobytes.
    gzip_buffers            16 8k;

    # This directive indicates that Gzip compression should be used for responses to clients that support HTTP version 1.1 and higher.
    gzip_http_version       1.1;

    # This directive sets a minimum length for responses to be eligible for Gzip compression. Responses with content smaller than this length won't be compressed.
    gzip_min_length         1000;

    # This directive specifies the MIME types of responses that should be compressed. The provided list includes various text-based content types such as plain text, CSS, JSON, JavaScript, XML, and more. Responses with these MIME types will be compressed before being sent to clients.
    gzip_types              text/plain text/css application/json application/x-javascript application/javascript text/xml application/xml application/xml+rss text/javascript;


    ############### # brotli

    # This directive enables Brotli compression for responses. When set to "on," Nginx will compress eligible responses using the Brotli compression algorithm before sending them to clients that support it.
    # brotli                  on;

    # This directive sets the compression level for Brotli. The value "6" indicates the compression level, which balances compression efficiency and speed. You can adjust this value based on your preference for compression ratio versus performance.
    # brotli_comp_level       6;

    # This directive enables Brotli pre-compression of static files. When set to "on," Nginx will automatically pre-compress static files (like CSS, JavaScript, etc.) using Brotli and store both the original and compressed versions on disk. This allows Nginx to serve the pre-compressed version when requested by a Brotli-capable client.
    # brotli_static           on;

    # This directive specifies the MIME types of responses that should be compressed using Brotli. The provided list includes various content types such as plain text, CSS, JSON, JavaScript, images (PNG, SVG, JPEG, etc.), fonts (woff, woff2), and more. Responses with these MIME types will be compressed using Brotli before being sent to clients.
    # brotli_types            text/plain text/css application/json                        application/x-javascript application/javascript text/xml application/xml application/xml+rss text/javascript image/png image/svg+xml image/x-icon image/jpeg font/woff font/woff2;


    # Rate Limiting based on zone for 10m (1,60,000 stored IP addresses) and for each unique IP 30 requests per second

    #  The zone uses 20 megabytes of memory to store information about IP addresses and their request rates. Each unique IP address is limited to a rate of 50 requests per second. If an IP address exceeds this rate, their requests will be subject to rate limiting.
    limit_req_zone $binary_remote_addr zone=ratelimit:20m  rate=50r/s;

    upstream node_servers {
        server node_server_1:3000;
        server node_server_2:3000;
        server node_server_3:3000;
        server node_server_4:3000;
        # Add more servers as needed
    }

    server {
        listen 80;
        server_name dockernode.com;
        # Redirect HTTP to HTTPS
        return 301 https://$host$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name dockernode.com;

        ssl_certificate /etc/nginx/ssl/localhost.crt;
        ssl_certificate_key /etc/nginx/ssl/localhost.key;

        # Additional SSL configuration here, such as protocols, ciphers, etc.

        location / {
            proxy_pass http://node_servers;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_cache_bypass $http_upgrade;
        }
}
}
